
### General Questions

#### Job failed: [Errno 26] Text file busy: '/tmp/lava/...'

This is the result of an S3 race condition. Essentially it's a lava internal
error that should not happen.

The [PAYLOAD_SETTLING_TIME](#general-configuration-parameters) can help control
this.

#### No payload files downloaded from S3

The payload prefix specified does not refer to any objects in S3. It generally
means the payload value in the job specification is incorrect. Note that this
value is always relative to the payloads area in S3, not absolute.

#### Recursive download not supported

This error can occur for multiple job types that involve downloading a payload
from the payload area in S3.

It occurs if the specified payload points to an S3 prefix that has nested
*folders* underneath (in the sense that S3 fakes the notion of *folder*).

#### Overlapping runs for the same job

When a lava job is dispatched, a run ID (UUID) is assigned at the time of
dispatch and a dispatch message is placed onto the job SQS queue for the target
worker.

The lava worker must complete the job, successfully or otherwise, before the SQS
queue message visibility timeout expires, otherwise the job will be re-queued by
SQS for another run. The re-run will have the same run configuration, including
run ID.

If multiple instances of a job run are active at the same time, it is likely
that the job is running longer than the SQS worker queue visibility timeout.

Options in this situation are (in order of preference):

1.  Redesign the job to run more efficiently so it completes within the message
    visibility period.

2.  Use the `timeout` parameter on the job where available so that lava will
    kill the job before the message visibility timeout expires.

3.  Set the [max_tries](#the-jobs-table) field in the job
    specification.

4.  Increase the visibility timeout on the worker SQS queue. This should be done
    by updating the CloudFormation stack for the worker. SQS limits the
    visibility timeout to a maximum of 12 hours.

#### What timezone applies when a job is run?

Lava controls the timezone when a job is dispatched as it's obviously important
that a job is run at the correct time.

Lava does not control the timezone in which a job executes and lava makes no
promises about the timezone of the execution environment.

If a job runs natively on a lava worker, it will generally inherit the timezone
of the host, which can be anything. If it runs as a [docker](#job-type-docker)
job it may have a different timezone to the host.

The bottom line is that jobs need to either:

1.  Avoid any timezone dependency in the execution environment (e.g. by always
    working with UTC or timezone aware timestamps); or

2.  Explicitly control the execution timezone. For [cmd](#job-type-cmd),
    [docker](#job-type-docker), [exe](#job-type-exe) and [pkg](#job-type-pkg)
    jobs, this can be done by specifying the `TZ` environment variable in the
    `env` parameter of the job specification. e.g.

```json
{
    "type": "exe",
    "payload": "...",
    "env": {
        "TZ": "Australia/Darwin"
    }
}
```

Danger signs in a job payload are usage of the **date(1)** command or use of
`datetime.datetime.now()` in a Python script.


#### Why are timezones all over the place in event records?

Records in the [events](#the-events-table) table contain a bunch of different
timestamps that may appear to have a random selection of timezones associated
with them.

Timezone aware timestamps are not all rendered into UTC for two reasons:

1.  The timezone information can sometimes be useful when investigating issues.

2.  There is no particular need to convert to UTC as the timestamp is
    unambiguous.

This why they have the timezones that they do.

|Field|Timezone Explanation|
|-|-----|
|ts\_event|This timezone aware timestamp is generated by the job execution environment. For most jobs, the timezone is that of the host running the lava worker. For [docker](#job-type-docker) jobs, it is the timezone of the container, which may be different from the host.|
|ts\_dispatch|This timezone aware timestamp is generated by the job dispatch environment. For scheduled jobs, this is the timezone of the host running the dispatch command via **cron(8)** and is unrelated to the timezone associated with the job schedule. For jobs dispatched by the [dispatch helper](#the-dispatch-helper) or [s3trigger](#dispatching-jobs-from-s3-events), the dispatch event comes from an AWS lambda function and the associated timezone is UTC. For [directly dispatched](#direct-dispatch) jobs, the timezone will be whatever timezone the dispatching entity happens to have.|
|tu\_event|This is the timezone naive equivalent of `ts_event` in UTC. It's present purely as a convenience.|
|ttl|This is a lava internal field. Its the UNIX epoch timestamp used by DynamoDB to automatically expire and remove old event records. Don't touch it or bother trying to interpret it.|

