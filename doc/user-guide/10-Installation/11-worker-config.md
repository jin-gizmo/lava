
## Lava Worker Configuration

Lava worker configuration can be modified by setting a number of configuration 
variables. For a configuration variable named `xyz`, lava will use the first
value in the following sequence:

1.  An environment variable named `LAVA_XYZ`
2.  An `XYZ` entry under the `config` map of the
    [realms table](#the-realms-table)
3.  A default value as described below.

!!! info
    The environment and [realms table](#the-realms-table) are only read when the
    worker starts. Changing configuration variables requires the worker to be
    restarted. Sorry.

In the following, a **Duration** is a string in the form `nnX` where `nn`
is a number and `X` is `s` (seconds), `m` (minutes) or `h` (hours), `d` (days)
or `w` (weeks).

A **Size** is a string in the form `nnX` where `nn` is a number and `X` is a
case-sensitive unit specifier:

*   `B`: Bytes (default if no unit specified)
*   `K`, `KB`: Kilobytes (1000)
*   `M`, `MB`: Megabytes
*   `G`, `GB`: Gigabytes
*   `T`, `TB`: Terabytes
*   `P`, `PB`: Petabytes.
*   `KiB`: Kibibytes (1024)
*   `MiB`: Mebibytes
*   `GiB`: Gibibytes
*   `TiB`: Tebibytes
*   `PiB`: Pebibytes.

A *boolean* is a case-insensitive string in the form:

*   `true`, `t`, `yes`, `y` or a non-zero integer (True)
*   `false`, `f`, `no`, `n` or zero (False).

### General Configuration Parameters { data-toc-label="General Configuration" }

|Name|Type|Default|Description|
|-|-|-|-----|
|CHECK_FOR_ZOMBIES|Boolean|True|When the worker exits, it waits for all the job threads to complete. On rare occasions, a thread may hang and delay the exit unnecessarily. If this parameter is set to True, an additional check is made a few times to see if there are any worker temporary directories still present. If there are none, then it's assumed the worker can safely exit.|
|CONN_APP_NAME|String|`lv-{{realm}}-{{job_id}}`|A Jinja template used to generate database client connection identifiers. It is rendered with the realm name, job ID and connection ID. See [Database Client Application Identification](#database-client-application-identification).|
|CW_METRICS_JOB|Boolean|False|If True, the worker will generate CloudWatch custom metric data for all jobs. Can be overridden (to enable or disable) at the job level as described [below](#cloudwatch-metrics).|
|CW_METRICS_PERIOD|Duration|`1m`|Period for generation of CloudWatch custom metric data for the worker itself. There is no point in setting this to anything less than 1 minute.|
|CW_METRICS_WORKER|Boolean|False|If True, the worker will generate CloudWatch custom metric data for the worker itself as described [below](#cloudwatch-metrics).|
|CW_NAMESPACE|String|`lava`|The namespace used for CloudWatch custom metrics generated by the worker.|
|DEBUG|Boolean|False|If True, some additional information is placed in the [events table](#the-events-table) for failed jobs.|
|DISPATCHER|String|-->|Fully qualified name for the lava dispatcher executable. Defaults to `/usr/local/bin/lava-dispatcher`.|
|EVENT_TTL|Duration|`2d`|Time to live for records in the DynamoDB [events table](#the-events-table).|
|HEARTBEAT_FILE|String|`.heartbeat`|File name (relative to `TMPDIR`) that will be touched once every cycle of the worker heartbeat. This is essentially a keep-alive on `TMPDIR` so some O/S cleanup process doesn't blow it away due to inactivity. As this is part of the heartbeat process, it is only effective if the worker is running using the `-b` / `--heartbeat` option.|
|ITERATION_MAX_DELAY|Duration|`5m`|Maximum allowed delay when rerunning a failed job.|
|ITERATION_MAX_LIMIT|Duration|10|Maximum allowed number of run attempts for a job.|
|JOB_LOCAL_TMPDIR|Boolean|True|If True, the `TMPDIR` environment variable will be set for [cmd](#job-type-cmd), [exe](#job-type-exe) and [pkg](#job-type-pkg) jobs to point into the private temporary run area for each job. If False, the system default value of `TMPDIR` is used.|
|JUMPSTART_DELAY|Duration|`15s`|Delay the initial [scheduler jump-start process](#jump-starting-the-scheduler) to allow the worker to fully initialise.|
|LOGLEVEL|String|`info`|The default logging level.|
|PARAM_CACHE_SIZE|Integer|`100`|Size of the cache for SSM parameters. Must be > 0.|
|PARAM_CACHE_TTL|Duration|`2m`|SSM parameter values are only cached for the specified duration.|
|PAYLOAD_DOWNLOADER|String|`v2`|Selects either payload downloader version. Allowed values are `v1` (deprecated) or `v2`. See [Job Payloads](#job-payloads) for more information.|
|PAYLOAD_SETTLING_TIME|Integer|1|Wait this many seconds before attempting to use a payload downloaded from S3. This helps avoid the occasional *text file busy* error. If this error is appearing, try setting this to 1 or 2 seconds. (Yes, it's a kludge. Sue me.)|
|SES_CONFIGURATION_SET|String|None|SES Configuration Set name for SES email sent by lava.|
|SES_FROM|String|None|Source email address for SES email sent by lava.|
|SES_REGION|String|`us-east-1`|AWS region for the Simple Email Service (SES).|
|SQS_MAX_DELAY_MINS|Integer|`15`|Maximum allowed delay for an SQS message in minutes. This is an AWS constraint.|
|STATE_MAX_TTL|Duration|`366d`|The maximum allowed time-to-live duration for an item in the [state](#the-state-table) table.|
|STATE_TTL|Duration|`7d`|The default time-to-live duration for an item in the [state](#the-state-table) table.|
|STDERR_SIZE|Size|`1024`|The number of bytes read from stderr when running jobs to include in the DynamoDB [events table](#the-events-table). The full contents of stderr are saved in S3. If > 0, data is read from the start of the file. If < 0, data is read from the end of the file. The latter is often more useful as that is typically where a fatal error message is found.|
|TMPDIR|String|`/tmp/lava`|Lava temporary directory for creating private run spaces for jobs. Not to be confused with the `TMPDIR` environment variable.|

### Configuration for [cmd](#job-type-cmd) Jobs { data-toc-label="cmd Jobs" }

|Name|Type|Default|Description|
|-|-|-|----|
|CMD_TIMEOUT|Duration|`10m`|Run timeout for the job.|

### Configuration for [dag](#job-type-dag) Jobs { data-toc-label="dag Jobs" }

|Name|Type|Default|Description|
|-|-|-|----|
|DAG_MAX_WORKERS|Duration|4 \* CPU count|Maximum allowed number of worker threads for dag jobs.|
|DAG_WORKERS|Duration|CPU count|Default number of worker threads for dag jobs.|

### Configuration for [db_from_s3](#job-type-db_from_s3) Jobs { data-toc-label="db_from_s3 Jobs" }

|Name|Type|Default|Description|
|-|-|-|----|
|PG_COPY_TIMEOUT|Duration|`30m`|Timeout for individual client side copy operations for Postgres.|

### Configuration for [docker](#job-type-docker) Jobs { data-toc-label="docker Jobs" }

|Name|Type|Default|Description|
|-|-|-|----|
|DOCKER_TIMEOUT|Duration|`10m`|Run timeout for the container.|

### Configuration for [exe](#job-type-exe) Jobs { data-toc-label="exe Jobs" }

|Name|Type|Default|Description|
|-|-|-|----|
|EXE_MAX_PAYLOAD_SIZE|Duration|`10M`|Maximum payload size.|
|EXE_TIMEOUT|Duration|`10m`|Run timeout for the job.|

### Configuration for [foreach](#job-type-foreach) Jobs { data-toc-label="foreach Jobs" }

|Name|Type|Default|Description|
|-|-|-|----|
|FOREACH\_LIMIT|Integer|10|The default limit on loop iterations for a [foreach](#job-type-foreach) job. This can be overridden in the job specification.|
|FOREACH\_MAX\_LIMIT|Integer|25|The maximum limit on loop iterations for a [foreach](#job-type-foreach) job. This cannot be overridden in the job specification.|


### Configuration for [pkg](#job-type-pkg) Jobs { data-toc-label="pkg Jobs" }

|Name|Type|Default|Description|
|-|-|-|----|
|PKG_MAX_PAYLOAD_SIZE|Size|`20M`|Maximum payload size.|
|PKG_TIMEOUT|Duration|`10m`|Run timeout for the job.|
|PKG_UNPACK_TIMEOUT|Duration|`30s`|Timeout for unpacking the job payload after downloading from S3.|

### Configuration for [sharepoint](#job-type-sharepoint_get_list) Jobs { data-toc-label="sharepoint Jobs" }

The `SP_LIST_*` parameters relate to conversion between SharePoint lists and
columnar data files.

|Name|Type|Default|Description|
|-|-|-|----|
|SP_LIST_DELIMITER|String|`|` (pipe)|Single character field delimiter.|
|SP_LIST_DOUBLEQUOTE|Boolean|`False`|As for Python csv.writer.|
|SP_LIST_ESCAPECHAR|String|None|As for Python csv.writer.|
|SP_LIST_QUOTING|String|`minimal`|As for csv.writer `QUOTE_*` parameters (without the QUOTE\_ prefix). Default `minimal` (i.e. `QUOTE_MINIMAL`).|
|SP_LOGGING|Boolean|`False`|Enable enhanced logging for the Sharepoint connector.|

### Configuration for [sql](#job-type-sql), [sqli](#job-type-sqli) and [sqlv](#job-type-sqlv) Jobs { data-toc-label="sql, sqli and sqlv Jobs" }

|Name|Type|Default|Description|
|-|-|-|----|
|SQL_BATCH_SIZE|Integer|`1000`|Number of rows to fetch in one go.|
|SQL_DELIMITER|String|`|` (pipe)|Single character field delimiter for data output.|
|SQL_DIALECT|String|`excel`|As for Python csv.writer.|
|SQL_DOUBLEQUOTE|Boolean|`False`|As for Python csv.writer.|
|SQL_ESCAPECHAR|String|None|As for Python csv.writer.|
|SQL_MAX_PAYLOAD_SIZE|Size|`100k`|Maximum payload size. ([sql](#job-type-sql) and [sqlv](#job-type-sqlv) only.)|
|SQL_OUTPUT_SUFFIX|String|`.out`|Suffix for output files. ([sql](#job-type-sql), [sqli](#job-type-sqli) only.)|
|SQL_QUOTING|String|`minimal`|As for csv.writer `QUOTE_*` parameters (without the QUOTE\_ prefix). Default `minimal` (i.e. `QUOTE_MINIMAL`).|

The following parameters are specific to [sqlc](#job-type-sqlv) 
jobs:

|Name|Type|Default|Description|
|-|-|-|----|
|SQLV_TIMEOUT|Duration|`10m`|Run timeout for the job.|

### Configuration for [sqlc](#job-type-sqlc) Jobs { data-toc-label="sqlc Jobs" }

|Name|Type|Default|Description|
|-|-|-|----|
|SQLC_MAX_PAYLOAD_SIZE|Size|`100k`|Maximum payload size.|
|SQLC_TIMEOUT|Duration|`10m`|Run timeout for the job.|

### Configuration for the [aws](#connector-type-aws) Connector { data-toc-label="aws Connector" }

|Name|Type|Default|Description|
|-|-|-|----|
|AWS\_ACCESS\_KEY\_CACHE\_SIZE|Integer|`20`|Size of the cache for AWS access keys.|
|AWS\_ACCESS\_KEY\_CACHE\_TTL|Duration|`10m`|AWS access keys are cached for the specified duration. This **must** be less than the duration for session credentials and should be significantly less.|
|AWS\_CONN\_DURATION|Duration|`3h`|The default session duration for AWS session credentials obtained by assuming an IAM role. This can be overridden in individual [aws](#connector-type-aws) connections.|

### Configuration for the [email](#connector-type-email) Connector { data-toc-label="email Connector" }

|Name|Type|Default|Description|
|-|-|-|----|
|EMAIL\_MAX\_ATTACHMENT\_SIZE|Size|`2M`|Maximum allowed size of any single attachment in bytes.|
|EMAIL\_MAX\_SIZE|Size|`5M`|Maximum allowed size of an email message in bytes. This includes the headers, body and attachments.|
|EMAIL\_MAX\_ATTACHMENTS|Integer|`5`|Maximum number of attachments per email message. Set to zero to disable attachments entirely.|


### Configuration for the [redshift](#connector-type-redshift) Connector { data-toc-label="redshift Connector" }

|Name|Type|Default|Description|
|-|-|-|----|
|RS_PASSWORD_DURATION|Duration|`15m`|Password validity period when obtaining temporary IAM credentials for Redshift provisioned clusters using [GetClusterCredentials](https://docs.aws.amazon.com/redshift/latest/mgmt/generating-iam-credentials-steps.html).|

Note the same parameter is used for an equivalent purpose for the
[redshift-serverless](#configuration-for-the-redshift-serverless-connector) connector.

### Configuration for the [redshift-serverless](#connector-type-redshift-serverless) Connector { data-toc-label="redshift-serverless Connector" }

|Name|Type|Default|Description|
|-|-|-|----|
|RS_PASSWORD_DURATION|Duration|`15m`|Password validity period when obtaining temporary IAM credentials for Redshift Serverless clusters using [GetCredentials](https://docs.aws.amazon.com/redshift-serverless/latest/APIReference/API_GetCredentials.html).|

Note the same parameter is used for an equivalent purpose for the
[redshift](#configuration-for-the-redshift-connector) connector.

## Lambda Function Configuration

The lambda functions use the same configuration mechanisms as described above
for the lava worker with the exception that they do not read any configuration
from the [realms table](#the-realms-table). 

Setting configuration values to non-default values must be done by setting the
corresponding `LAVA_*` environment variable on the lambda function itself.

### Configuration for [s3trigger](#dispatching-jobs-from-s3-events)

|Name|Type|Default|Description|
|-|-|-|----|
|S3TRIGGER_CACHE_TTL|Duration|`60s`|The [s3trigger lambda](#dispatching-jobs-from-s3-events) will cache lookup results on the [s3triggers](#the-s3triggers-table) and [jobs](#the-jobs-table) tables for the specified duration. A zero duration disables caching.|
|S3TRIGGER_DEDUP_CACHE_SIZE|Integer|`0`|The number of entries in the [s3trigger deduplication](#s3-event-deduplication) cache. Setting this to `0` disables deduplication.|
|S3TRIGGER_DEDUP_TTL|Duration|`30s`|The time to live for entries in the [s3trigger deduplication](#s3-event-deduplication) cache.|
|SQS_MAX_DELAY_MINS|Integer|`15`|Maximum allowed delay for an SQS message in minutes. This is an AWS constraint.|

